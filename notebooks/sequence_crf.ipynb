{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "source": [
      "Tutorial 5: Training a CRF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "from collections import namedtuple\n",
      "import pydecode.model as model\n",
      "import pydecode.chart as chart"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The emission probabilities.\n",
      "emission = {'ROOT' : {'ROOT' : 1.0},\n",
      "            'the' :  {'D': 0.8, 'N': 0.1, 'V': 0.1},\n",
      "            'dog' :  {'D': 0.1, 'N': 0.8, 'V': 0.1},\n",
      "            'walked':{'V': 1},\n",
      "            'in' :   {'D': 1},\n",
      "            'park' : {'N': 0.1, 'V': 0.9},\n",
      "            'END' :  {'END' : 1.0}}\n",
      "\n",
      "# The transition probabilities.\n",
      "transition = {'D' :    {'D' : 0.1, 'N' : 0.8, 'V' : 0.1, 'END' : 0},\n",
      "              'N' :    {'D' : 0.1, 'N' : 0.1, 'V' : 0.8, 'END' : 0},\n",
      "              'V' :    {'D' : 0.4, 'N' : 0.3, 'V' : 0.3, 'END' : 0},\n",
      "              'ROOT' : {'D' : 0.4, 'N' : 0.3, 'V' : 0.3}}"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Bigram(namedtuple(\"Bigram\", [\"position\", \"tag\", \"prevtag\"])):\n",
      "    def __str__(self): return \"%s -> %s\"%(self.prevtag, self.tag)\n",
      "    \n",
      "    @staticmethod\n",
      "    def from_tagging(tagging):\n",
      "        return [Bigram(i, tag=tag, prevtag=tagging[i-1])\n",
      "                for i, tag in enumerate(tagging)]\n",
      "      \n",
      "class Tagged(namedtuple(\"Tagged\", [\"position\", \"word\", \"tag\"])):\n",
      "    def __str__(self): return \"%s %s\"%(self.word, self.tag)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sequence_dynamic_program(sentence, c):\n",
      "    words = [\"ROOT\"] + sentence + [\"END\"]\n",
      "    c.init(Tagged(0, \"ROOT\", \"ROOT\"))\n",
      "    for i, word in enumerate(words[1:], 1):\n",
      "        prev_tags = emission[words[i-1]].keys()\n",
      "        for tag in emission[word].iterkeys():\n",
      "            c[Tagged(i, word, tag)] = \\\n",
      "                c.sum([c[key] * c.sr(Bigram(i - 2, tag, prev))\n",
      "                       for prev in prev_tags \n",
      "                       for key in [Tagged(i - 1, words[i - 1], prev)] \n",
      "                       if key in c])\n",
      "    return c"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = chart.ChartBuilder(lambda a:a, chart.HypergraphSemiRing, \n",
      "                       build_hypergraph = True)\n",
      "hypergraph = sequence_dynamic_program([\"the\", \"dog\"], c).finish()\n",
      "for edge in hypergraph.edges:\n",
      "    print hypergraph.label(edge)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ROOT -> V\n",
        "ROOT -> D\n",
        "ROOT -> N\n",
        "V -> V\n",
        "D -> V\n",
        "N -> V\n",
        "V -> D\n",
        "D -> D\n",
        "N -> D\n",
        "V -> N\n",
        "D -> N\n",
        "N -> N\n",
        "V -> END\n",
        "D -> END\n",
        "N -> END\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TaggingCRFModel(model.DynamicProgrammingModel):\n",
      "    def dynamic_program(self, sentence, c):\n",
      "        return sequence_dynamic_program(sentence, c) \n",
      "\n",
      "    def factored_psi(self, sentence, bigram):\n",
      "        print bigram, sentence\n",
      "        return {#\"word-1:%s\"%sentence[bigram.position - 1] if bigram.position != 0 else \"\", \n",
      "                \"word:%s\" % sentence[bigram.position], \n",
      "                \"tag-1:%s\" % bigram.prevtag, \n",
      "                \"tag:%s\" % bigram.tag}"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_X = map(lambda a: a.split(),\n",
      "             [\"the dog walked END\",\n",
      "              \"in the park END\",\n",
      "              \"in the dog END\"])\n",
      "data_Y = map(lambda a: Bigram.from_tagging(a.split()),\n",
      "             [\"D N V\", \"I D N\", \"I D N\"])\n",
      "\n",
      "hm = TaggingCRFModel()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pystruct.learners import StructuredPerceptron\n",
      "sp = StructuredPerceptron(hm)\n",
      "sp.fit(data_X, data_Y)"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name SubgradientSSVM",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-978c39e40e7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpystruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearners\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStructuredPerceptron\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSubgradientSSVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneSlackSSVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: cannot import name SubgradientSSVM"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from  pystruct.plot_learning import plot_learning\n",
      "plot_learning(sp)"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'StructuredPerceptron' object has no attribute 'objective_curve_'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-43ce9c57b049>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m  \u001b[0mpystruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_learning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pystruct/plot_learning.pyc\u001b[0m in \u001b[0;36mplot_learning\u001b[1;34m(ssvm, time)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'base_ssvm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mssvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mssvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_ssvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iterations: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective_curve_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Objective: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mssvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective_curve_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0minference_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'StructuredPerceptron' object has no attribute 'objective_curve_'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "StructuredPerceptron(average=False, batch=False, decay_exponent=0,\n",
        "           decay_t0=10, logger=None, max_iter=100,\n",
        "           model=TaggingCRFModel, size_psi: 13, n_jobs=1, verbose=0)\n"
       ]
      }
     ]
    }
   ]
  }
 ]
}